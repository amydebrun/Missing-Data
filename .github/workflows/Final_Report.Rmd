---
title: Estimating Treatment Effects in Longitudinal Clinical Trials with Missing Data 
authors:
  - name: Amy Browne
    thanks: The authors would like to thank Neil O'Leary from the University of Galway for his valuable guidance, feedback, and support throughout the development of this project
    department: Department of Methametics
    affiliation: University of Galway
    email: k.yip2@universityofgalway.ie
  - name: Tsz Mang Yip
    department: Department of Methametics
    affiliation: University of Galway
    email: a.browne47@universityofgalway.ie
abstract:
  - Motivation. Missing data is a pervasive issue in longitudinal clinical trials, risking bias and reduced power. This study compares several statistical methods for estimating treatment effects in the presence of missing data.
  - Result. No meaningful differences between methods for both data sets. To understanding there are many ways to handle missing data, and it is crutial to understand the mechanism to make corret choise under circumstances.
  - Supplement information. Code Available at https://github.com/amydebrun/Missing-Data
keywords:
  - Missing Data
  - Longitudinal Data
  - Randomized Clinical Trial
  - Real World Data Analysis
bibliography: references.bib
biblio-style: unsrt
output: rticles::arxiv_article
header-includes:
  - \newcommand{\pandocbounded}[1]{#1}
---

```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
library(mice)
library(tidyverse)
library(haven)
library(lme4)
library(broom.mixed)
library(meta)
library(dplyr)
library(naniar)
library(tidymodels)
library(gtsummary)
library(tinytex)
library(ggdag)
suppressWarnings({
  source("R scripts/Functions.R")
  source("R scripts/VITAL data formats.R")
  source("R scripts/Acupuncture data formats.R")
  source("R scripts/Summary analysis.R")
  source("R scripts/Category time analysis.R")
  source("R scripts/Continuous time analysis.R")
  source("R scripts/Different Imputation Method.R")
  source("R scripts/Sens_analysis_cat.R")
  source("R scripts/Sens_analysis_cont.R")
  source("R scripts/Sens_analysis_combined.R")
  source("R scripts/Data_summary.R")
})
```


# Introduction

## Missing data in longitudinal study

*Longitudinal Study Design*

Longitudinal studies are a type of research design in which repeated measures of variables are collected from participants over different time points. They provide a comprehensive understanding of the direction and degree of change over time, typically in years or even decades. While the information provided in longitudinal studies is beneficial for establishing relationships, the nature of the design faces challenges while attempting to retain the participants involved in the study. 

Longitudinal trials requires data to be collected from participants over set time points using a consistent method of collection. It is important that the researchers attempt to maximize the design so non-contact or non-cooperation is unlikely. However missing data is almost inevitable due to the study duration and complexity. 

Clinical trials are bio medical or behavioural research studies that study the effect of certain interventions or treatment on participants. These trials are also subject to missing participant data which could be due to time consumption, illness or family commitments. This can be an issue as loss of data can reduce robustness of the results. Ignoring the missing data altogether introduces bias in to the results as we are choosing to ignore informative data even if we did not observe it. Removing the missing data unavoidably reduces the sample size of the study therefore reducing statistical power which is important in establishing a valid treatment effect. 
  
## Missing mechanism
  
Missing data mechanisms are important to consider when choosing which sort of missing data handling method to use. There are three mechanisms which missing data can follow:

- Missing Completely At Random (MCAR)
- Missing At Random (MAR)
- Missing Not At Random (MNAR)

Although they may appear similar at first glance, continuing to handle missing data without considering these mechanisms may still result in biased estimates and inaccurate conclusions. Missing data mechanisms appear to be mentioned first by Donald Rubin in 1976. We can formally define these mechanisms using the following notation;

- $R$ represents a missing data indicator which when $R=1$ indicates observed data and $R=0$ indicates unobserved
- $X$ represents data that is always observed 
- $Y$ represents data that is potentially missing. 

**Missing Completely At Random**

The formal definition of MCAR data is:

$$\quad P(R = 1 \mid Y, X) = P(R = 1)$$
The probability of the data is observed given observed data and missing data is the same as the probability of being observed without the given data. This mechanism is considered the easiest to deal with as it does not bias the result although data is rarely MCAR. This can occur due to system failure and some data is deleted accidentally, or else there is issues with the treatment system and data cannot be recorded.    


**Missing At Random**

$$\quad P(R = 1 \mid Y, X) = P(R = 1 \mid X)$$
The probability of data being observed given the rest of the data is the same as the probability being observed given the observed data. In short, the data's missingness is dependent on the observed data. For example, people with a higher body mass index may be more prone to having missing blood pressure data - this is not relative to the missing data. MAR is a more realistic mechanism than MCAR and requires more intensive handling methods. 


**Missing Not At Random**

$$\quad P(R = 1 \mid Y, X) \ne P(R = 1 \mid X)$$
The probability of data being observed is not dependent on the observed data. This mechanism is the most difficult to deal with as it relates to the unobserved data, so producing valid results is a challenge. Certain participants in a general health study may avoid answering questions truthfully about smoking habits or their diet in order to make themselves more appealing. Sensitivity analysis is an option to determine the treatment effect when assuming different mechanisms. 

  - DAG of missing mechanism (randomised) in progress in R scripts 
  
  
## Different missing data patterns (section tbc)

A missing data pattern describes the pattern of missing data among the observed data. 
As described by Little & Rubin (2014), it's important to remark the missing data patterns of the data set prior to data handling as some handling methods are intended for certain classified patterns.  

-univariate missing data

Univariate missing data confines the missingness to a single variable 

-multivariate missing data
-monotonic 
-general
-file matching
-factor analysis 
 
## Current approach and limitations
 
  - Existing literature reveals inconsistent reporting and handling practices.(Power 2014)
  - Consequences: bias, reduced efficiency, invalid conclusions if not handled properly.
  

## Objective of this project

  - Using statistical principled methods
  - Test how different methods perform in estimating treatment effects using real-world data.

# Data sets

We have sourced two different data sets to perform our analysis on. They both have different sample sizes and different levels of missing data which is an advantage as we can conduct analysis in different settings. 

**Acupuncture Data**

*Source*
  
Vickers et al. published a paper in 2004 on a trial they conducted to determine the effect of acupuncture therapy on chronic headache in primary care. Vickers released the dataset from the study in 2006 and is publicly available  to download in excel format from https://pmc.ncbi.nlm.nih.gov/articles/PMC1489946/.

*Study Design*

The study design for the acupuncture trial is a longitudinal randomised controlled trial with two follow up time points. 401 participants were gathered from general practices in England and Wales who suffered from migraines. 

*Data*

13 variables were recorded during the acupuncture trial. 

```{r}
acu_var_table
```

Variables `pk2` and ``pk5` are the follow-up times at 3 months and 12 months. 

```{r}
acu_summary
acu_sex_plot
acu_age_plot
```


```{r}
acu_pk1_plot
acu_pk2_plot
acu_pk5_plot
```

*Original Estimand*

The aim of the original study was to estimate the effect of acupuncture therapy on chronic headache in comparison to general care. Therefore, our estimand with the sourced data set is the difference in mean headache score at the final time point of 12 months between the acupuncture group and the control group. This is modelled parsimoniously by

$$\small\text{pk5}_i = \beta_0 + \beta_1 \text{group}_i + \beta_2 \text{pk1}_i + \varepsilon_i$$
where

- $pk5_i$ is the headache severity of individual $i$ at 12 months. 
- $\beta_0$ is our intercept parameter when there is no treatment group and no recorded baseline headache severity. 
- $\beta_1$ is the effect of the treatment group. This is our treatment effect of interest. 
- $\beta_2$ is the effect of the baseline headache severity
- $\varepsilon_i$ is the residual error term for individual $i$

**VITAL data**  - missing baseline data (vital)

*Source*

MacFarlane et al. conducted a study on the therapeutic effects of vitamin D and fish oil on osteoarthritic knee pain. We sourced this data at xyz. 

*Study Design* 

This study was a 2x2 factorial designed longitudinal randomised controlled trial. 1,398 participants in the study was randomised to 4 possible treatment combinations. Participants were randomised to receive either omega-3 oils or vitamin D, both treatments, or randomised to the placebo group. For this research project, we assumed that that the participants were only randomised to either recieve the fish oil treatment, vitamin D treatment or the placebo. We did not include the interaction between vitamin D or the fish oil. 

|                   | Vitamin D              | Placebo          |
|-------------------|------------------------|------------------|
| **Fish Oil**      | N = 342 (not analysed) | N = 353          |
| **Placebo**       | N = 332                | N = 371          |


  - Data overview

```{r}
vital_summary
age_vital_plot
bmi_vital_plot
sex_vital_plot
```

```{r}
pain_base_vital_plot
pain_yr1_vital_plot
pain_yr2_vital_plot
pain_yr3_vital_plot
pain_yr4_vital_plot
```
    
*Original estimand in VITAL study*

Our estimand for this dataset is the difference in mean knee pain at the final time point of 4 years post randomisation $pain_yr4$ which is modelled by 
$$\text{pain_yr4}_i = \beta_0 + \beta_1\text{fishoilactive}_i + \beta_2\text{vitdactive}_i + \beta_3\text{pain_base}_i \varepsilon_i$$ in which

- $text{pain_yr4}_i$ is the knee pain score for individual $i$ at the final time point of 4 years post randomisation. 
- $\beta_0$ is the intercept parameter which represents the knee pain score when there is no treatment of vitamin D or fish oil given and no baseline knee pain score is recorded. 
- $\beta_1$ is the effect of being randomised to the fishoil treatment group. This is the treatment effect of interest in our fishoil only missingness analysis. 
- $\beta_2$ is the effect of being randomised to the vitamin D treatment group. This is the treatment effect of interest in our vitamin D only missingness analysis. 
- $\beta_3$ is the effect of the baseline knee pain score pre-randomisation. 
- $\varepsilon$ is the residual error of individual $i$ 

## Missing analysis

**Acupuncture Data**

```{r}
acu_miss_perc_plot
```
```{r}
acu_miss_perc_group
```

```{r}
acu_miss_pattern_plot
```

**VITAL data**

```{r}
vital_miss_perc_plot
```
```{r}
vital_miss_perc_plot_fish
```
```{r}
vital_miss_pattern_fish
```

  - Missing proportion
  - Missing pattern
  - which methods to use based on data
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
  
  
# Methods

## Data wrangling

-   Have data both in wide and long format
-   We have done multi-imputation in wide format then transform for LME
-   Which account for repeat measurements and will work if collecting
    time are more different
-   Show our data wrangling codes

## Anchoring methods

-   We start off with basic methods for the sake of comparison

### Complete case analysis

-   Given our estimand here is the change of pain score at the end of
    study, we fit that against group and baseline pain score.

-   Show our lm() function for each data sets

-   If data are MCAR, valid inference can be obtained from xxx completed
    record in xxx data sets

-   We did not adjust for other baseline covariates for the simplicity
    and saving computing power

-   We will leave out those baseline covariates in other methods too for
    comparison

-   For CAA, though MCAR assumptions are not always strictly required,
    especially if we fit more baseline covariates into the model

-   Still, rows are moved and we are not using all the observed data we
    have, so we can till have biased estimation with MAR

-   We can say in CAA, the assumption is the outcome is MAR dependent on
    predictors

-   This assumption can be called "conditionally MCAR", which it's still
    a strong assumption

    -   The missingness depends only on variables included in the model
    -   The model is correctly specified
    -   The outcome variable is not involved in the missingness
        mechanism (same as MAR).

**(Based on my understanding, need to be checked, maybe more suitable to
put in Amy's part)**

Y MAR depends on X (predictors in model) $$\begin{align*}
  Pr(Ri=r \mid Yi, Xi) = Pr(Ri=r \mid Xi)
  \end{align*}$$ Thus, we can infer under MAR, the distribution of
income within job type is the same in the observed data, the unobserved
data, and the population. $$\begin{align*}
  & Pr(Yi \mid Ri=r, Xi) \\ 
  & = \displaystyle \frac{Pr(Ri=r,Yi,Xi)}{Pr(Ri=r,Xi)} \\
  & = \displaystyle \frac{Pr(Ri=r \mid Yi,Xi)Pr(Yi,Xi)}{Pr(Ri=r \mid Xi)Pr(Xi)} 
  \\
  & Assuming \ \ \Pr(Ri=r \mid Yi, Xi) = Pr(Ri=r \mid Xi) \\
  & = \displaystyle \frac{Pr(Yi,Xi)}{Pr(Xi)} \\
  & = Pr(Yi \mid Xi)
  \end{align*}$$

-   The issue here is we would like to include as much information as we
    can in the X to have a more robust MAR
-   Using more statistical principle method, we will be able to do that
-   However, it cannot be tested, and that is why we need sensitive
    analysis

### Last observation carry forward

-   Based on assumptions unrelated to missing mechanisms
-   LOCF assuming the outcome stabilized once missed
-   Which could be valid under certain circumstances
-   Not convincing in both data sets here
-   Show our code to do LOCF in wide format

### Mean observation method

-   Also based on assumptions unrelated to missing mechanisms
-   Mean method assuming the observed data mean value correctly present
    the population mean
-   Arguably a even more radical assumption compared to data MCAR
-   Show our mean method code

## Changing imputation methods

### No imputation

-   complete case, LME

### Single imputation

-   LOCF, mean observation

### Multiple imputation

-   Why we need multiple? (To quantify our uncertainty of prediction)

#### Rubin's rules

-   Used for pooling parameter and variance
-   Compute K data sets
-   Fit the substantive model to the kth imputed data set, this gives
    $\hat{\beta}_{k}$ and $\hat{\sigma}_{k}^{2}$
-   Then calculate $\hat{\beta}_{MI}$ and $\hat{V}_{MI}$
-   To test hypothesis $\hat{\beta}_{MI} = \beta^{0}$ we refer to a
    t-distribution, ts=T with $\nu$ degrees of freedom
-   We thus have the p value and CI95%
-   We can also use$(\frac{I_{C} - I_{O}}{I_{C}}) * 100%$ to quantify
    the information $\beta$ lost due to missing data **Q: Better way for
    comparison different imputation methods?**

$$\begin{align*}
  \hat{\beta}_{MI} = \frac{1}{K} \sum_{k=1}^{K}{\hat{\beta}_{k}} \\
  \hat{V}_{MI} = \hat{W} + (1 + \frac{1}{K}) \hat{B} \\
  \hat{W} = \frac{1}{K} \sum^{K}_{k=1}{\hat{\sigma}^{2}_{k}} \\
  \hat{B} = \frac{1}{K-1} \sum^{K}_{k=1}({\hat{\beta}_{k}} - 
  \hat{\beta_{MI}})^{2} \\
  T = \frac{\hat{\beta}_{MI} - \beta^{0}}  {\sqrt{\hat{V}_{MI}}} \\
  \nu = (K-1)[1 + \frac{\hat{W}}{(1 + 1/K) \hat{B}}]^{2}
  \end{align*}$$

#### Sequential regression MI

-   if missing pattern close to monotonic (assuming Amy introduced
    previously)
-   which is a common situation in practice, missing considered as
    withdrawal
-   justification, consider the joint distribution

$$\begin{align*}
    f(Y_{i,1},Y_{i,2},...,Y_{i,p}) = f(Y_{i,p} \mid Y_{i,1},...,Y_{i,p-1}) * 
    f(Y_{i,p-1} \mid Y_{i,1},...,Y_{i,p-2}) * ... * f(Y_{i,2} \mid Y_{i,1}) 
    * f(Y_{i,1})
    \end{align*}$$

-   with monotonic pattern, MAR means each conditional distribution
    valid from the observed data algorithm
-   Suppose we have i individual with j variables
-   Monotonic means for each unobserved $Y_{i,j}$ have
    $Y_{i,1},...,Y_{i,j-1}$ observed

$$\begin{align*}    
    Y_{i,j} = (1,Y_{i,1},...,Y_{i,j-1})^{T} * \beta_{j} + 
    e_{i,j},\ {e_{i,j}^{i.i.d.} \sim{N} (0,\sigma^{2}_{j})}
    \end{align*}$$

-   By ordinary least squares we have
    $\hat{\beta}_{j},\hat{\sigma}_{j}^{2}$
-   Then draw $\beta_{j}^{*},\sigma_{j}^{*2}$

$$\begin{align*}
   \sigma_j^{*2} = \frac{\hat{\sigma}_j^2 (n_j - j)}{z} \\
   \beta^* \sim N(\hat{\beta}, \sigma_j^{*2} A_j) \\
   A_j = (\sum_{i=1}^{n_j} x_{i,j} x_{i,j}^T)^{-1}
   \end{align*}$$

-   Impute $Y_{i,j} = (1,Y_{i,1},...,Y_{i,j-1}) \beta^{*} + e^{*}_{i,j}$
-   Repeat for $Y_{i,j+1}$ until complete
-   We can use this method for acupuncture but not VITAL
-   If non-monotonic then Joint model or FCS

#### Joint modelling

-   no assumption of missing pattern
-   assuming missing mechanism ignorable
-   thus multivariate normal $Y \sim N(\beta,\ \Omega)$
    $Y = (Y_{i,1},Y_{i,2},...,Y_{i,p})^{T}$
    $\beta = (\beta_{0,1},\beta_{0,2},...,\beta_{0,p})^{T}$ $\Omega$ is
    the covariance matrix
-   Gibbs sampler is on apporach to estimate the parameters
-   Drawing each parameter in turn, conditional on all thers parameters
    and the data
-   As prior we calculate from observed data $\beta^{0},\Omega^{0}$
    missing value draw from observed value of the same variable $Y_{j}$,
    with replacement, denoted as $Y_{M}^{0}$ thus calculate
    $\overline{Y}^{0}$ and $S^{0}$ (which is also $S_{P}$)
-   for iteration r

$$\begin{align*}
  \Omega^{-1,r} \sim W(n + \nu, (S_p^{-1} + S^{r-1})^{-1}) \\
  \beta^{r} \sim N(\bar{Y}^{r-1}, n^{-1} \Omega^r) \\
  Y_{M}^{r} \sim f(Y_{M} \mid \beta^{r}, \Omega^{r}, Y_{O}) \\
  \bar{Y}^{r} = \text{mean}(Y_M^{r}, Y_{O}) \\
  S^{r} = \text{sum of squares and cross products from}(Y_M^{r}, {Y_O}).
  \end{align*}$$

-   after n times iteration as burn, repeat k times and pool by Rubin's
    rules

#### Full conditional specification

-   Similar to sequential but relaxing the requirement that all
    covariate values in the sequential regressions are observed

-   We note that if the missingness pattern is monotone, then FCS is
    equivalent to sequential regression imputation

-   The name ‘full conditional specification’ was coined because each
    variable is imputed from its full conditional distribution on all
    the other variables.

-   We first re-order variables so the missingness patter is as close to
    monotone as possibile

-   Then the cycle goes like: filling missing by drawing, with
    replacement, from the observed values of each variable regress the
    observed part of $Y_{j}$ on all remaining variable, with missing
    value imputed use the regression to impute the missing value of
    $Y_{j}$

#### FCS VS joint modelling

-   More generally, under the multivariate normal distribution, the
    joint distribution defines the unique conditional distributions, and
    vice versa. So the two specifications are compatible.
-   In general, joint model with Gibbs sampling is a more efficient
    algorithms.
-   Joint model do have the benefit of including prior information
-   Joint model can also use ridge parameter to stabilize the covariance
    matrix if we have relative large p compared to sample size
-   However, we do not have these concerns in our project so we will use
    FCS for our MI.
-   FCS easily to implement as ti avoid the need to define prior, and
    generally take less iteration for convergence.
-   We use FCS with MICE package for our MI in this project
-   for FCS, we can use different methods (predictive value or observed
    value)
-   will explore later

#### How to choose m

-   $\gamma0$ is a important parameter for choosing m. But unknown in
    our project and most cases
-   Bodner 2008 suggest use the proportion of complete cases as
    conservative estimate of $\gamma0$

Chose 3-5 m

-   The classic advice is to use a low number of imputations, somewhere
    between 3 and 5, for moderate amounts of missing information.
-   (Rubin 1987b, 114) Argument of low m based on the variance estimate
    T with m imputations $T_{m} = (1 + \frac{\gamma0}{m}) T_{\infty}$
-   Only limited advantage of increase m further (e.g. for
    $\gamma0=30\%$, m=5, $T_m=1.06T_\infty$) - We start with m=5 as MICE
    default setting in our project

Chose m\>20

-   Several authors investigated the influence of m
-   The picture emerging from this work is that it is often beneficial
    to set mm higher, somewhere in the range of 20–100 imputations.
-   (Royston 2004) suggested use
    $\text{Coefficient of Variation}(ln(t_{\nu}\sqrt{T})) < 0.05$
    constrain uncertainty of confidence interval roughly within 10%,
    require m\>20
-   (Graham 2007) argues that to attain power within 1% of theoretical
    power, we need m\>20
-   (Bodner 2008) explore the relationship between m and r0, p-value,
    and 95%CI. for $\gamma0=(0.1, 0.3, 0.5, 0.7, 0.9)$ he recommend
    $m=(3,6,12,24,59,114,258)$ respectively.
-   Setting mm very high (say m=200m=200) may be useful for low-level
    estimands that are very uncertain, and for which we want to
    approximate the full distribution, or for parameters that are
    notoriously different to estimates, like variance components. - On
    the other hand, setting mm high may not be worth the extra wait if
    the primary interest is on the point estimates (and not on standard
    errors, pp-values, and so on). In that case using m=5−20 will be
    enough under moderate missingness.

$m \approx 100\lambda$

-   White, Royston, and Wood (2011)

-   The rule has now become the de-facto standard, especially in medical
    applications.

-   The number of imputations should be similar to the percentage of
    cases that are incomplete - When missing fraction \<0.5, following
    properties will hold

    -   The Monte Carlo error of $\hat{\beta}$ is approximately 10% of
        SE
    -   The Monte Carlo error of
        $\hat{\beta}/SE_{\hat{\beta}} \approx 0.1$
    -   The Monte Carlo error of the p-value is approximately 0.01 when
        the true p-value is 0.05

-   One problem is when p increase, will have large % of missing
    individuals. Can use missing rate as conservative estimate

## Changing substantive model

-   Simple linear regression
-   LME
-   Change estimand
-   Change linear regression to polynomial, splie...

## Examing using forest plot

-   We use several forest plot to show how our estimand changes between
    methods
-   First plot compared 6 methods...
-   2nd plot we changed estimand... ...
-   3rd plot we change MI methods
-   At its simplest, this means regressing the response on the constant
    alone, which estimates its marginal mean.

## Sensitive analysis

-   Violation of MAR possible
-   shifting method (choosing delta, how to model)

```{r}
delta_combined_cont_cat_plot
```
```{r}
SA_combined_vital_all_plot 
```


# Result

## Comparing different methods

## Changing estimand

## Changing imputation methods

## Sensitive analysis

## Missing data in clinical research

# Discussion

-   No meaningful difference observed
-   Change estimand: Almost no impact in acupuncture study due to 2
    follow-up

## Limitations

-   limitation: only 2 follow up for acupuncture
-   limitation: VITAL only have weak therapeutic effect

## Future work

-   further work: simulate complete data, and compare accuracy between
    methods























# Back up writing

## Missing Data Mechanisms



## Data 

We will analyse 2 longitudinal randomised controlled trials. Both studies are designed differently with two different sample sizes, which is an advantage to our research as we can look to apply these methods in two different settings. 

## Acupuncture for chronic headache in primary care: large, pragmatic, randomised trial (Vickers et al., 2004)

**Study Design**

Vickers et al. conducted a longitudinal randomised controlled trial to determine the effect of acupuncture therapy on headache against a placebo. 

**Characteristics**

table summary

**Missing Data**


-estimands 

## The Effects of Vitamin D and Marine Omega-3 Fatty Acid Supplementation on Chronic Knee Pain in Older US Adults: Results From a Randomized Trial (MacFarlane et al. 2020)

**Study Design**

**Characteristics**

table summary

**Missing Data**

- estimand 

## Methods

## Complete Case Analysis

- method 
mechanism

## Single Imputation

mean
locf 
mechanism

## Maximum Likelihood

- linear mixed effects model
- conditions 
- only suitable with missing outcome 
mechanism

## Multiple Imputation

- chained equations 
mechanism

## Sensitivity Analysis 

We conducted a sensitivity analysis on both data sets to determine how sensitive the estimated in the treatment effect is when we assume the data is Missing Not At Random. 

**Purpose of Sensitivity Analysis**

As mentioned in our background section, it is important to investigate the missingness mechanism of the data to assess the choice of data handling method. Although we can never really confirm what type of missingness mechanism follows, we can use sensitivity analysis to test how the data forms under different missingness assumptions. 

**Delta Adjustment**

This is a common approach of sensitivity analysis. A fixed $\delta$ is added or removed from the values that were imputed using multiple imputation using chained equations. Doing this, we are estimating the effect that treatment had on the patient if they were observed. Providing a range of deltas allows potential for unobserved patients responses to treatment to be worse or better than the observed patients. 

**Choosing δ**

In our analysis, we chose which range of $\delta$ values to use based on the outcome of the observed values of each data set. A quantitative estimate would involve determining the mean value of the outcome and the mean predicted value of the missing outcome. 

**Acupuncture**

**VITAL**


## Results 

forest plots 
table of estimates 
sensitivity analysis 


