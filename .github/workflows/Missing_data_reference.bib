
@article{baker_systematic_2025,
	title = {A systematic review of reporting and handling of missing data in observational studies using the {UNOS} database},
	volume = {44},
	issn = {1053-2498, 1557-3117},
	url = {https://www.jhltonline.org/article/S1053-2498(24)01932-6/abstract},
	doi = {10.1016/j.healun.2024.10.023},
	language = {English},
	number = {3},
	urldate = {2025-06-12},
	journal = {The Journal of Heart and Lung Transplantation},
	author = {Baker, William L. and Moore, Timothy E. and Baron, Eric and Kittleson, Michelle and Parker, William F. and Jaiswal, Abhishek},
	month = mar,
	year = {2025},
	pmid = {39521197},
	note = {Publisher: Elsevier},
	keywords = {cohort, heart transplantation, methods, missing data, UNOS},
	pages = {462--468},
}

@article{powney_review_2014,
	title = {A review of the handling of missing longitudinal outcome data in clinical trials},
	volume = {15},
	issn = {1745-6215},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4087243/},
	doi = {10.1186/1745-6215-15-237},
	abstract = {The aim of this review was to establish the frequency with which trials take into account missingness, and to discover what methods trialists use for adjustment in randomised controlled trials with longitudinal measurements. Failing to address the problems that can arise from missing outcome data can result in misleading conclusions. Missing data should be addressed as a means of a sensitivity analysis of the complete case analysis results. One hundred publications of randomised controlled trials with longitudinal measurements were selected randomly from trial publications from the years 2005 to 2012. Information was extracted from these trials, including whether reasons for dropout were reported, what methods were used for handing the missing data, whether there was any explanation of the methods for missing data handling, and whether a statistician was involved in the analysis. The main focus of the review was on missing data post dropout rather than missing interim data. Of all the papers in the study, 9 (9\%) had no missing data. More than half of the papers included in the study failed to make any attempt to explain the reasons for their choice of missing data handling method. Of the papers with clear missing data handling methods, 44 papers (50\%) used adequate methods of missing data handling, whereas 30 (34\%) of the papers used missing data methods which may not have been appropriate. In the remaining 17 papers (19\%), it was difficult to assess the validity of the methods used. An imputation method was used in 18 papers (20\%). Multiple imputation methods were introduced in 1987 and are an efficient way of accounting for missing data in general, and yet only 4 papers used these methods. Out of the 18 papers which used imputation, only 7 displayed the results as a sensitivity analysis of the complete case analysis results. 61\% of the papers that used an imputation explained the reasons for their chosen method. Just under a third of the papers made no reference to reasons for missing outcome data. There was little consistency in reporting of missing data within longitudinal trials.},
	urldate = {2025-06-15},
	journal = {Trials},
	author = {Powney, Matthew and Williamson, Paula and Kirkham, Jamie and Kolamunnage-Dona, Ruwanthi},
	month = jun,
	year = {2014},
	pmid = {24947664},
	pmcid = {PMC4087243},
	pages = {237},
	file = {Full Text:C\:\\Users\\abrow\\Zotero\\storage\\WLBUECBL\\Powney et al. - 2014 - A review of the handling of missing longitudinal outcome data in clinical trials.pdf:application/pdf},
}

@book{carpenter_multiple_2023,
	edition = {2},
	series = {Statistics in {Practice}},
	title = {Multiple {Imputation} and its {Application}},
	isbn = {978-1-119-75608-8},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119756118},
	urldate = {2025-05-11},
	publisher = {Wiley},
	author = {Carpenter, James R. and Bartlett, Jonathan W. and Morris, Tim P. and Wood, Angela M. and Quartagno, Matteo and Kenward, Michael G.},
	month = aug,
	year = {2023},
}

@article{white_multiple_2011,
	title = {Multiple imputation using chained equations: {Issues} and guidance for practice},
	volume = {30},
	issn = {1097-0258},
	shorttitle = {Multiple imputation using chained equations},
	doi = {10.1002/sim.4067},
	abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments.},
	number = {4},
	journal = {Statistics in Medicine},
	author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
	month = feb,
	year = {2011},
	pmid = {21225900},
	keywords = {Adolescent, Adult, Aged, Cardiovascular Diseases, Cholesterol, Female, HDL, Humans, Lipoproteins, Mental Health, Middle Aged, Models, Multicenter Studies as Topic, Statistical, Young Adult},
	pages = {377--399},
}

@article{von_hippel_how_2009,
	title = {How to {Impute} {Interactions}, {Squares}, and {Other} {Transformed} {Variables}},
	volume = {39},
	issn = {1467-9531},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9531.2009.01215.x},
	doi = {10.1111/j.1467-9531.2009.01215.x},
	abstract = {Researchers often carry out regression analysis using data that have missing values. Missing values can be filled in using multiple imputation, but imputation is tricky if the regression includes interactions, squares, or other transformations of the regressors. In this paper, we examine different approaches to imputing transformed variables; and we find one simple method that works well across a variety of circumstances. Our recommendation is to transform, then impute—i.e., calculate the interactions or squares in the incomplete data and then impute these transformations like any other variable. The transform-then-impute method yields good regression estimates, even though the imputed values are often inconsistent with one another. It is tempting to try and “fix” the inconsistencies in the imputed values, but methods that do so lead to biased regression estimates. Such biased methods include the passive imputation strategy implemented by the popular ice command for Stata.},
	number = {1},
	urldate = {2025-06-05},
	journal = {Sociological Methodology},
	author = {Von Hippel, Paul T.},
	year = {2009},
	pages = {265--291},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9531.2009.01215.x},
}

@article{graham_how_2007,
	title = {How many imputations are really needed? {Some} practical clarifications of multiple imputation theory},
	volume = {8},
	issn = {1389-4986},
	shorttitle = {How many imputations are really needed?},
	doi = {10.1007/s11121-007-0070-9},
	abstract = {Multiple imputation (MI) and full information maximum likelihood (FIML) are the two most common approaches to missing data analysis. In theory, MI and FIML are equivalent when identical models are tested using the same variables, and when m, the number of imputations performed with MI, approaches infinity. However, it is important to know how many imputations are necessary before MI and FIML are sufficiently equivalent in ways that are important to prevention scientists. MI theory suggests that small values of m, even on the order of three to five imputations, yield excellent results. Previous guidelines for sufficient m are based on relative efficiency, which involves the fraction of missing information (gamma) for the parameter being estimated, and m. In the present study, we used a Monte Carlo simulation to test MI models across several scenarios in which gamma and m were varied. Standard errors and p-values for the regression coefficient of interest varied as a function of m, but not at the same rate as relative efficiency. Most importantly, statistical power for small effect sizes diminished as m became smaller, and the rate of this power falloff was much greater than predicted by changes in relative efficiency. Based our findings, we recommend that researchers using MI should perform many more imputations than previously considered sufficient. These recommendations are based on gamma, and take into consideration one's tolerance for a preventable power falloff (compared to FIML) due to using too few imputations.},
	number = {3},
	journal = {Prevention Science: The Official Journal of the Society for Prevention Research},
	author = {Graham, John W. and Olchowski, Allison E. and Gilreath, Tamika D.},
	month = sep,
	year = {2007},
	pmid = {17549635},
	keywords = {Data Interpretation, Humans, Likelihood Functions, Models, Monte Carlo Method, Preventive Medicine, Sample Size, Statistical},
	pages = {206--213},
}

@book{noauthor_flexible_nodate,
	title = {Flexible {Imputation} of {Missing} {Data}},
	shorttitle = {https},
	url = {https://stefvanbuuren.name/fimd/sec-howmany.html},
	abstract = {Flexible Imputation of Missing Data, Second Edition},
	urldate = {2025-06-05},
}

@misc{noauthor_mice_nodate,
	title = {mice: {Passive} imputation and {Post}-processing},
	url = {https://www.gerkovink.com/miceVignettes/Passive_Post_processing/Passive_imputation_post_processing.html?utm_source=chatgpt.com},
	urldate = {2025-06-10},
}

@book{little_statistical_2002,
	address = {Newy York, UNITED STATES},
	title = {Statistical {Analysis} with {Missing} {Data}},
	isbn = {978-1-118-62586-6},
	url = {http://ebookcentral.proquest.com/lib/nuig/detail.action?docID=1775204},
	urldate = {2025-06-09},
	publisher = {John Wiley \& Sons, Incorporated},
	author = {Little, Roderick J. A. and Rubin, Donald B.},
	year = {2002},
	keywords = {Mathematical statistics., Missing observations (Statistics)},
}

@article{kaushal_missing_2014,
	title = {Missing data in clinical trials: {Pitfalls} and remedies},
	volume = {4},
	issn = {2229-516X},
	shorttitle = {Missing data in clinical trials},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4181137/},
	number = {Suppl 1},
	urldate = {2025-06-09},
	journal = {International Journal of Applied and Basic Medical Research},
	author = {Kaushal, Sandeep},
	month = sep,
	year = {2014},
	pmid = {25298948},
	pmcid = {PMC4181137},
	pages = {S6--S7},
}

@misc{noauthor_inference_nodate,
	title = {Inference and {Missing} {Data} on {JSTOR}},
	url = {https://www-jstor-org.nuigalway.idm.oclc.org/stable/2335739?sid=primo},
	urldate = {2025-06-09},
}

@article{noauthor_caruana_nodate,
	title = {Caruana, {E}. {J}., {Roman}, {M}., {Hernández}-{Sánchez}, {J}., \& {Solli}, {P}. (2015). {Longitudinal} studies. {Journal} of thoracic disease, 7(11), {E537}–{E540}. https://doi.org/10.3978/j.issn.2072-1439.2015.10.63},
}

@book{carpenter_mi_2023,
	edition = {2},
	series = {Statistics in {Practice}},
	title = {{MI} book 2},
	isbn = {978-1-119-75608-8},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119756118},
	urldate = {2025-05-11},
	publisher = {Wiley},
	author = {Carpenter, James R. and Bartlett, Jonathan W. and Morris, Tim P. and Wood, Angela M. and Quartagno, Matteo and Kenward, Michael G.},
	month = aug,
	year = {2023},
}

@article{von_hippel_how_2009-1,
	title = {How to {Impute} {Interactions}, {Squares}, and {Other} {Transformed} {Variables}},
	volume = {39},
	issn = {1467-9531},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9531.2009.01215.x},
	doi = {10.1111/j.1467-9531.2009.01215.x},
	abstract = {Researchers often carry out regression analysis using data that have missing values. Missing values can be filled in using multiple imputation, but imputation is tricky if the regression includes interactions, squares, or other transformations of the regressors. In this paper, we examine different approaches to imputing transformed variables; and we find one simple method that works well across a variety of circumstances. Our recommendation is to transform, then impute—i.e., calculate the interactions or squares in the incomplete data and then impute these transformations like any other variable. The transform-then-impute method yields good regression estimates, even though the imputed values are often inconsistent with one another. It is tempting to try and “fix” the inconsistencies in the imputed values, but methods that do so lead to biased regression estimates. Such biased methods include the passive imputation strategy implemented by the popular ice command for Stata.},
	number = {1},
	urldate = {2025-06-05},
	journal = {Sociological Methodology},
	author = {Von Hippel, Paul T.},
	year = {2009},
	pages = {265--291},
}

@book{noauthor_mi_nodate,
	title = {{MI} book},
	shorttitle = {https},
	url = {https://stefvanbuuren.name/fimd/sec-howmany.html},
	abstract = {Flexible Imputation of Missing Data, Second Edition},
	urldate = {2025-06-05},
}

@article{white_multiple_2011-1,
	title = {Multiple imputation using chained equations: {Issues} and guidance for practice},
	volume = {30},
	issn = {1097-0258},
	shorttitle = {Multiple imputation using chained equations},
	doi = {10.1002/sim.4067},
	abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments.},
	number = {4},
	journal = {Statistics in Medicine},
	author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
	month = feb,
	year = {2011},
	pmid = {21225900},
	keywords = {Adolescent, Adult, Aged, Cardiovascular Diseases, Cholesterol, Female, HDL, Humans, Lipoproteins, Mental Health, Middle Aged, Models, Multicenter Studies as Topic, Statistical, Young Adult},
	pages = {377--399},
}

@article{graham_how_2007-1,
	title = {How many imputations are really needed? {Some} practical clarifications of multiple imputation theory},
	volume = {8},
	issn = {1389-4986},
	shorttitle = {How many imputations are really needed?},
	doi = {10.1007/s11121-007-0070-9},
	abstract = {Multiple imputation (MI) and full information maximum likelihood (FIML) are the two most common approaches to missing data analysis. In theory, MI and FIML are equivalent when identical models are tested using the same variables, and when m, the number of imputations performed with MI, approaches infinity. However, it is important to know how many imputations are necessary before MI and FIML are sufficiently equivalent in ways that are important to prevention scientists. MI theory suggests that small values of m, even on the order of three to five imputations, yield excellent results. Previous guidelines for sufficient m are based on relative efficiency, which involves the fraction of missing information (gamma) for the parameter being estimated, and m. In the present study, we used a Monte Carlo simulation to test MI models across several scenarios in which gamma and m were varied. Standard errors and p-values for the regression coefficient of interest varied as a function of m, but not at the same rate as relative efficiency. Most importantly, statistical power for small effect sizes diminished as m became smaller, and the rate of this power falloff was much greater than predicted by changes in relative efficiency. Based our findings, we recommend that researchers using MI should perform many more imputations than previously considered sufficient. These recommendations are based on gamma, and take into consideration one's tolerance for a preventable power falloff (compared to FIML) due to using too few imputations.},
	number = {3},
	journal = {Prevention Science: The Official Journal of the Society for Prevention Research},
	author = {Graham, John W. and Olchowski, Allison E. and Gilreath, Tamika D.},
	month = sep,
	year = {2007},
	pmid = {17549635},
	keywords = {Data Interpretation, Humans, Likelihood Functions, Models, Monte Carlo Method, Preventive Medicine, Sample Size, Statistical},
	pages = {206--213},
}

@misc{noauthor_mice_nodate-1,
	title = {mice: {Passive} imputation and {Post}-processing},
	url = {https://www.gerkovink.com/miceVignettes/Passive_Post_processing/Passive_imputation_post_processing.html?utm_source=chatgpt.com},
	urldate = {2025-06-10},
}

@article{kaushal_missing_2014-1,
	title = {Missing data in clinical trials: {Pitfalls} and remedies},
	volume = {4},
	issn = {2229-516X},
	shorttitle = {Missing data in clinical trials},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4181137/},
	number = {Suppl 1},
	urldate = {2025-06-09},
	journal = {International Journal of Applied and Basic Medical Research},
	author = {Kaushal, Sandeep},
	month = sep,
	year = {2014},
	pmid = {25298948},
	pmcid = {PMC4181137},
	pages = {S6--S7},
}

@book{little_statistical_2002-1,
	address = {Newy York, UNITED STATES},
	title = {Statistical {Analysis} with {Missing} {Data}},
	isbn = {978-1-118-62586-6},
	url = {http://ebookcentral.proquest.com/lib/nuig/detail.action?docID=1775204},
	urldate = {2025-06-09},
	publisher = {John Wiley \& Sons, Incorporated},
	author = {Little, Roderick J. A. and Rubin, Donald B.},
	year = {2002},
	keywords = {Mathematical statistics., Missing observations (Statistics)},
}

@misc{noauthor_inference_nodate-1,
	title = {Inference and {Missing} {Data} on {JSTOR}},
	url = {https://www-jstor-org.nuigalway.idm.oclc.org/stable/2335739?sid=primo},
	urldate = {2025-06-09},
}

@article{noauthor_caruana_nodate-1,
	title = {Caruana, {E}. {J}., {Roman}, {M}., {Hernández}-{Sánchez}, {J}., \& {Solli}, {P}. (2015). {Longitudinal} studies. {Journal} of thoracic disease, 7(11), {E537}–{E540}. https://doi.org/10.3978/j.issn.2072-1439.2015.10.63},
}

@book{noauthor_httpsstefvanbuurennamefimd_nodate,
	title = {https://stefvanbuuren.name/fimd/},
	shorttitle = {https},
	url = {https://stefvanbuuren.name/fimd/},
	abstract = {Flexible Imputation of Missing Data, Second Edition},
	urldate = {2025-06-11},
}

@article{buuren_flexible_nodate,
	title = {Flexible {Imputation} of {Missing} {Data}},
	author = {Buuren, Stef van},
}

@article{graham_graham2007how_2007,
	title = {({Graham2007}){How} {Many} {Imputations} are {Really} {Needed}? {Some} {Practical} {Clarifications} of {Multiple} {Imputation} {Theory}},
	volume = {8},
	issn = {1573-6695},
	shorttitle = {How {Many} {Imputations} are {Really} {Needed}?},
	url = {https://doi.org/10.1007/s11121-007-0070-9},
	doi = {10.1007/s11121-007-0070-9},
	abstract = {Multiple imputation (MI) and full information maximum likelihood (FIML) are the two most common approaches to missing data analysis. In theory, MI and FIML are equivalent when identical models are tested using the same variables, and when m, the number of imputations performed with MI, approaches infinity. However, it is important to know how many imputations are necessary before MI and FIML are sufficiently equivalent in ways that are important to prevention scientists. MI theory suggests that small values of m, even on the order of three to five imputations, yield excellent results. Previous guidelines for sufficient m are based on relative efficiency, which involves the fraction of missing information (γ) for the parameter being estimated, and m. In the present study, we used a Monte Carlo simulation to test MI models across several scenarios in which γ and m were varied. Standard errors and p-values for the regression coefficient of interest varied as a function of m, but not at the same rate as relative efficiency. Most importantly, statistical power for small effect sizes diminished as m became smaller, and the rate of this power falloff was much greater than predicted by changes in relative efficiency. Based our findings, we recommend that researchers using MI should perform many more imputations than previously considered sufficient. These recommendations are based on γ, and take into consideration one’s tolerance for a preventable power falloff (compared to FIML) due to using too few imputations.},
	number = {3},
	urldate = {2025-06-11},
	journal = {Prevention Science},
	author = {Graham, John W. and Olchowski, Allison E. and Gilreath, Tamika D.},
	month = sep,
	year = {2007},
	keywords = {Distribution Theory, Full information maximum likelihood, Missing data, Model Theory, Multiple imputation, Number of imputations, Quantitative Psychology, Research on Associations, Statistical power, Statistical Theory and Methods, Statistics},
	pages = {206--213},
}

@article{von_hippel_how_2009-2,
	title = {How to {Impute} {Interactions}, {Squares}, and {Other} {Transformed} {Variables}},
	volume = {39},
	issn = {1467-9531},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9531.2009.01215.x},
	doi = {10.1111/j.1467-9531.2009.01215.x},
	abstract = {Researchers often carry out regression analysis using data that have missing values. Missing values can be filled in using multiple imputation, but imputation is tricky if the regression includes interactions, squares, or other transformations of the regressors. In this paper, we examine different approaches to imputing transformed variables; and we find one simple method that works well across a variety of circumstances. Our recommendation is to transform, then impute—i.e., calculate the interactions or squares in the incomplete data and then impute these transformations like any other variable. The transform-then-impute method yields good regression estimates, even though the imputed values are often inconsistent with one another. It is tempting to try and “fix” the inconsistencies in the imputed values, but methods that do so lead to biased regression estimates. Such biased methods include the passive imputation strategy implemented by the popular ice command for Stata.},
	number = {1},
	urldate = {2025-06-11},
	journal = {Sociological Methodology},
	author = {Von Hippel, Paul T.},
	year = {2009},
	pages = {265--291},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9531.2009.01215.x},
}

@article{von_hippel_von2009how_2009,
	title = {({Von2009}){How} to {Impute} {Interactions}, {Squares}, and {Other} {Transformed} {Variables}},
	volume = {39},
	issn = {1467-9531},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9531.2009.01215.x},
	doi = {10.1111/j.1467-9531.2009.01215.x},
	abstract = {Researchers often carry out regression analysis using data that have missing values. Missing values can be filled in using multiple imputation, but imputation is tricky if the regression includes interactions, squares, or other transformations of the regressors. In this paper, we examine different approaches to imputing transformed variables; and we find one simple method that works well across a variety of circumstances. Our recommendation is to transform, then impute—i.e., calculate the interactions or squares in the incomplete data and then impute these transformations like any other variable. The transform-then-impute method yields good regression estimates, even though the imputed values are often inconsistent with one another. It is tempting to try and “fix” the inconsistencies in the imputed values, but methods that do so lead to biased regression estimates. Such biased methods include the passive imputation strategy implemented by the popular ice command for Stata.},
	number = {1},
	urldate = {2025-06-11},
	journal = {Sociological Methodology},
	author = {Von Hippel, Paul T.},
	year = {2009},
	pages = {265--291},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9531.2009.01215.x},
}

@article{white_multiple_2011-2,
	title = {Multiple imputation using chained equations: {Issues} and guidance for practice},
	volume = {30},
	issn = {1097-0258},
	shorttitle = {Multiple imputation using chained equations},
	doi = {10.1002/sim.4067},
	abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments.},
	number = {4},
	journal = {Statistics in Medicine},
	author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
	month = feb,
	year = {2011},
	pmid = {21225900},
	keywords = {Adolescent, Adult, Aged, Cardiovascular Diseases, Cholesterol, Female, HDL, Humans, Lipoproteins, Mental Health, Middle Aged, Models, Multicenter Studies as Topic, Statistical, Young Adult},
	pages = {377--399},
}

@article{white_white2011multiple_2011,
	title = {({White2011}){Multiple} imputation using chained equations: {Issues} and guidance for practice},
	volume = {30},
	issn = {1097-0258},
	shorttitle = {Multiple imputation using chained equations},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4067},
	doi = {10.1002/sim.4067},
	abstract = {Multiple imputation by chained equations is a flexible and practical approach to handling missing data. We describe the principles of the method and show how to impute categorical and quantitative variables, including skewed variables. We give guidance on how to specify the imputation model and how many imputations are needed. We describe the practical analysis of multiply imputed data, including model building and model checking. We stress the limitations of the method and discuss the possible pitfalls. We illustrate the ideas using a data set in mental health, giving Stata code fragments. Copyright © 2010 John Wiley \& Sons, Ltd.},
	number = {4},
	urldate = {2025-06-11},
	journal = {Statistics in Medicine},
	author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
	year = {2011},
	keywords = {fully conditional specification, missing data, multiple imputation},
	pages = {377--399},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.4067},
}

@book{noauthor_rubin1987_1987,
	title = {({Rubin1987}) {Multiple} {Imputation} for {Nonresponse} in {Surveys}},
	isbn = {978-0-470-31669-6},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470316696.fmatter},
	abstract = {The prelims comprise: Title Copyright Introduction Acknowledgements Preface Table of Contents},
	urldate = {2025-06-11},
	publisher = {John Wiley \& Sons, Ltd},
	year = {1987},
	doi = {10.1002/9780470316696.fmatter},
	annote = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470316696.fmatter},
}

@article{royston_royston2004multiple_2004,
	title = {({Royston2004}){Multiple} {Imputation} of {Missing} {Values}},
	volume = {4},
	issn = {1536-867X},
	url = {https://doi.org/10.1177/1536867X0400400301},
	doi = {10.1177/1536867X0400400301},
	abstract = {Following the seminal publications of Rubin about thirty years ago, statisticians have become increasingly aware of the inadequacy of “complete-case” analysis of datasets with missing observations. In medicine, for example, observations may be missing in a sporadic way for different covariates, and a complete-case analysis may omit as many as half of the available cases. Hotdeck imputation was implemented in Stata in 1999 by Mander and Clayton. However, this technique may perform poorly when many rows of data have at least one missing value. This article describes an implementation for Stata of the MICE method of multiple multivariate imputation described by van Buuren, Boshuizen, and Knook (1999). MICE stands for multivariate imputation by chained equations. The basic idea of data analysis with multiple imputation is to create a small number (e.g., 5–10) of copies of the data, each of which has the missing values suitably imputed, and analyze each complete dataset independently. Estimates of parameters of interest are averaged across the copies to give a single estimate. Standard errors are computed according to the “Rubin rules”, devised to allow for the between- and within-imputation components of variation in the parameter estimates. This article describes five ado-files. mvis creates multiple multivariate imputations. uvis imputes missing values for a single variable as a function of several covariates, each with complete data. micombine fits a wide variety of regression models to a multiply imputed dataset, combining the estimates using Rubin's rules, and supports survival analysis models (stcox and streg), categorical data models, generalized linear models, and more. Finally, misplit and mijoin are utilities to intercon-vert datasets created by mvis and by the miset program from John Carlin and colleagues. The use of the routines is illustrated with an example of prognostic modeling in breast cancer.},
	number = {3},
	urldate = {2025-06-11},
	journal = {The Stata Journal},
	author = {Royston, Patrick},
	month = aug,
	year = {2004},
	pages = {227--241},
	annote = {Publisher: SAGE Publications},
}

@article{bodner_bodner2008what_2008,
	title = {({Bodner2008}){What} {Improves} with {Increased} {Missing} {Data} {Imputations}?},
	volume = {15},
	issn = {1070-5511},
	url = {https://doi.org/10.1080/10705510802339072},
	doi = {10.1080/10705510802339072},
	abstract = {When using multiple imputation in the analysis of incomplete data, a prominent guideline suggests that more than 10 imputed data values are seldom needed. This article calls into question the optimism of this guideline and illustrates that important quantities (e.g., p values, confidence interval half-widths, and estimated fractions of missing information) suffer from substantial imprecision with a small number of imputations. Substantively, a researcher can draw categorically different conclusions about null hypothesis rejection, estimation precision, and missing information in distinct multiple imputation runs for the same data and analysis with few imputations. This article explores the factors associated with this imprecision, demonstrates that precision improves by increasing the number of imputations, and provides practical guidelines for choosing a reasonable number of imputations to reduce imprecision for each of these quantities.},
	number = {4},
	urldate = {2025-06-11},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Bodner, Todd E.},
	month = oct,
	year = {2008},
	pages = {651--675},
	annote = {Publisher: Routledge \_eprint: https://doi.org/10.1080/10705510802339072},
}
